{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7624a02",
   "metadata": {},
   "source": [
    "###ASSIGNMENT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52563d",
   "metadata": {},
   "source": [
    "##RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca70a52",
   "metadata": {},
   "source": [
    "Importing the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "f9576aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34695d",
   "metadata": {},
   "source": [
    "Loading and Preparing the Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "1a7b0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X_df=pd.DataFrame(boston.data)\n",
    "y_df=pd.DataFrame(boston.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8931651",
   "metadata": {},
   "source": [
    "Splitting the Data into Training and Test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "01ebca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df,y_df,random_state=530)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513827dd",
   "metadata": {},
   "source": [
    "a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b353f",
   "metadata": {},
   "source": [
    "Function to create Bootstrapped training sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "f8d855f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bootstrapp(X,y):\n",
    "    b_indices = np.random.randint(low=0, high=len(X), size=len(X))\n",
    "    y1=y.rename(columns={0:\"13\"})\n",
    "    Train_df = pd.concat([X,y1],axis=1)\n",
    "    BTS =  Train_df.iloc[b_indices]\n",
    "    return BTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "27042dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.13642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489</td>\n",
       "      <td>5.891</td>\n",
       "      <td>22.3</td>\n",
       "      <td>3.9454</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>10.87</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2.77974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>4.903</td>\n",
       "      <td>97.8</td>\n",
       "      <td>1.3459</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>29.29</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>15.57570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580</td>\n",
       "      <td>5.926</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.9084</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>368.74</td>\n",
       "      <td>18.13</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.13117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>6.127</td>\n",
       "      <td>85.2</td>\n",
       "      <td>2.1224</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>387.69</td>\n",
       "      <td>14.09</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.07022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.020</td>\n",
       "      <td>47.2</td>\n",
       "      <td>3.5549</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>393.23</td>\n",
       "      <td>10.11</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.05479</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472</td>\n",
       "      <td>6.616</td>\n",
       "      <td>58.1</td>\n",
       "      <td>3.3700</td>\n",
       "      <td>7.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>393.36</td>\n",
       "      <td>8.93</td>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2.77974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>4.903</td>\n",
       "      <td>97.8</td>\n",
       "      <td>1.3459</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>29.29</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.14476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.547</td>\n",
       "      <td>5.731</td>\n",
       "      <td>65.2</td>\n",
       "      <td>2.7592</td>\n",
       "      <td>6.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>391.50</td>\n",
       "      <td>13.61</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.17446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.489</td>\n",
       "      <td>5.960</td>\n",
       "      <td>92.1</td>\n",
       "      <td>3.8771</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>393.25</td>\n",
       "      <td>17.27</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.06588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>7.765</td>\n",
       "      <td>83.3</td>\n",
       "      <td>2.7410</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>395.56</td>\n",
       "      <td>7.56</td>\n",
       "      <td>39.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1      2    3      4      5     6       7     8      9  \\\n",
       "205   0.13642   0.0  10.59  0.0  0.489  5.891  22.3  3.9454   4.0  277.0   \n",
       "144   2.77974   0.0  19.58  0.0  0.871  4.903  97.8  1.3459   5.0  403.0   \n",
       "468  15.57570   0.0  18.10  0.0  0.580  5.926  71.0  2.9084  24.0  666.0   \n",
       "107   0.13117   0.0   8.56  0.0  0.520  6.127  85.2  2.1224   5.0  384.0   \n",
       "176   0.07022   0.0   4.05  0.0  0.510  6.020  47.2  3.5549   5.0  296.0   \n",
       "..        ...   ...    ...  ...    ...    ...   ...     ...   ...    ...   \n",
       "305   0.05479  33.0   2.18  0.0  0.472  6.616  58.1  3.3700   7.0  222.0   \n",
       "144   2.77974   0.0  19.58  0.0  0.871  4.903  97.8  1.3459   5.0  403.0   \n",
       "119   0.14476   0.0  10.01  0.0  0.547  5.731  65.2  2.7592   6.0  432.0   \n",
       "210   0.17446   0.0  10.59  1.0  0.489  5.960  92.1  3.8771   4.0  277.0   \n",
       "180   0.06588   0.0   2.46  0.0  0.488  7.765  83.3  2.7410   3.0  193.0   \n",
       "\n",
       "       10      11     12    13  \n",
       "205  18.6  396.90  10.87  22.6  \n",
       "144  14.7  396.90  29.29  11.8  \n",
       "468  20.2  368.74  18.13  19.1  \n",
       "107  20.9  387.69  14.09  20.4  \n",
       "176  16.6  393.23  10.11  23.2  \n",
       "..    ...     ...    ...   ...  \n",
       "305  18.4  393.36   8.93  28.4  \n",
       "144  14.7  396.90  29.29  11.8  \n",
       "119  17.8  391.50  13.61  19.3  \n",
       "210  18.6  393.25  17.27  21.7  \n",
       "180  17.8  395.56   7.56  39.8  \n",
       "\n",
       "[379 rows x 14 columns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bootstrapp(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2886179",
   "metadata": {},
   "source": [
    "Class for Node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "8afea320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, ft_index=None, threshold=None, left=None, right=None, variance=None, value=None):        \n",
    "        #below are necessary for the decision node\n",
    "        self.ft_index = ft_index\n",
    "        self.threshold = threshold   #this is the value for the considered feature\n",
    "        self.left = left      #gives the left child from the decision node\n",
    "        self.right = right    #gives the right child from the decision node\n",
    "        self.variance = variance #stores the variance for the particular split node     \n",
    "        #below is necessary for the leaf node\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75e899",
   "metadata": {},
   "source": [
    "Class for Decicion Tree to implement Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "d0b93b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    def __init__(self, min_samples_split=2, height=2):\n",
    "        self.root = None  #considered as the starting point\n",
    "        #below are the conditions to end the build tree, if not overfitting might occur\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.height = height\n",
    "    \n",
    "    def fit(self, dataset):\n",
    "        #This is just a function used to pass dataset, which calls build tree for the decision tree\n",
    "        self.root = self.build_tree(dataset.values)\n",
    "        \n",
    "    def build_tree(self, dataset,curr_depth=0):        \n",
    "        #this function is a recursive function used to built the tree\n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        \n",
    "        best_split = {}\n",
    "        # Stopping conditions are checked until which the tree will be built\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.height:\n",
    "            # Now we find the best split possible for the tree \n",
    "            best_split = self.best_split(dataset, num_samples,num_features)\n",
    "            # check if information gain is positive\n",
    "            if best_split[\"variance\"]>0:\n",
    "                #Recurring for the left tree\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                #Recurring for the right tree\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                #Return the node\n",
    "                return Node(best_split[\"ft_index\"], best_split[\"threshold\"], \n",
    "                            left_subtree, right_subtree, best_split[\"variance\"])\n",
    "        \n",
    "        #To calculate the average value of y of all points belonging to a particular leaf \n",
    "        \n",
    "        leaf_value = np.mean(Y)\n",
    "        Node(value=leaf_value)\n",
    "        # return leaf node\n",
    "        return Node(value=leaf_value)\n",
    "       \n",
    "    \n",
    "    def best_split(self, dataset, num_samples,num_features):\n",
    "        #This function returns a dictionary \n",
    "        best_split = {}\n",
    "        max_variance = -float(\"inf\")\n",
    "        n_rows,n_cols = dataset.shape \n",
    "        column = list(range(n_cols-1))\n",
    "        sample_feats = random.sample(population=column,k=5)\n",
    "        #A sample of attributes is considered at each node (p/3) approx 5 attributes\n",
    "        \n",
    "        #We loop through all the features and we traverse through all possible values that we have encountered(unique)\n",
    "        \n",
    "        for ft_index in sample_feats:\n",
    "            ft_vals = dataset[:, ft_index]\n",
    "            uniq_thresh = np.unique(ft_vals)\n",
    "            # loop over all the feature values present in the data\n",
    "            for threshold in uniq_thresh:\n",
    "                \n",
    "                #This function is to split the left and right datasets\n",
    "                dataset_left, dataset_right = self.split(dataset, ft_index, threshold)\n",
    "                # check if childs are not null\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    #Using variance to calculate the information gain as it is a regression method\n",
    "                    curr_variance = self.variance_reduction(y, left_y, right_y)\n",
    "                    #We update the best split dictionary with the below values when the current variance is greater\n",
    "                    #than the previous variance \n",
    "                    if curr_variance>max_variance:\n",
    "                        best_split[\"ft_index\"] = ft_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"variance\"] = curr_variance\n",
    "                        max_variance = curr_variance\n",
    "                    \n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, ft_index, threshold):\n",
    "\n",
    "        dataset_left = np.array([row for row in dataset if row[ft_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[ft_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def variance_reduction(self, parent, l_child, r_child):\n",
    "        #We subtract the combined variance of left and right from the combined variance of the parent \n",
    "        prob_left = len(l_child) / len(parent)\n",
    "        prob_right = len(r_child) / len(parent)\n",
    "        reduction = np.var(parent) - (prob_left * np.var(l_child) + prob_right * np.var(r_child))\n",
    "        return reduction\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        preds = [self.predictions(x, self.root) for x in X]\n",
    "        return preds\n",
    "    \n",
    "    def predictions(self, x, tree):\n",
    "        \n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.ft_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.predictions(x, tree.left)\n",
    "        else:\n",
    "            return self.predictions(x, tree.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d172f2",
   "metadata": {},
   "source": [
    "b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c5bd0",
   "metadata": {},
   "source": [
    "Using each BTS to train for each tree, where a sample of (p/3) attributes= approx 5 attributes where used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "a226f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = RandomForest(min_samples_split=3,height=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "aac67a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X,y,n_trees,height):\n",
    "  \n",
    "    for i in range(n_trees):\n",
    "        BTS = Bootstrapp(X,y)    \n",
    "        tree = F.fit(BTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd577ea",
   "metadata": {},
   "source": [
    "c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa486711",
   "metadata": {},
   "source": [
    "MSE for training set and test set: B=100, height=3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "724fe147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.943677400421517\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train,y_train,100,3)\n",
    "Y_pred = F.predict(X_train.values) \n",
    "mse_tr=np.sqrt(mean_squared_error(y_train.values, Y_pred))\n",
    "print(mse_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "86ca26d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.836106071169423\n"
     ]
    }
   ],
   "source": [
    "Y_pred1 = F.predict(X_test.values) \n",
    "mse_te=np.sqrt(mean_squared_error(y_test.values, Y_pred1))\n",
    "print(mse_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200e305",
   "metadata": {},
   "source": [
    "d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d40dc8",
   "metadata": {},
   "source": [
    "MSE for different values of B and h:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "3a3f8323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B=[100,120,130,140,150]\n",
    "tr_vals=[]\n",
    "te_vals=[]\n",
    "for i in B:\n",
    "    random_forest(X_train,y_train,i,3)\n",
    "    Y_pred = F.predict(X_train.values)\n",
    "    tr=np.sqrt(mean_squared_error(y_train.values, Y_pred))\n",
    "    tr_vals.append(tr)\n",
    "    Y_pred1 = F.predict(X_test.values)\n",
    "    te=np.sqrt(mean_squared_error(y_test.values, Y_pred1))\n",
    "    te_vals.append(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "996889aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.363627565306588,\n",
       " 4.367071693444946,\n",
       " 4.4176333203706335,\n",
       " 5.076211808775973,\n",
       " 4.162304171765976]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "2293899f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.132018486564442,\n",
       " 5.317334300619827,\n",
       " 5.634915438725028,\n",
       " 5.639025350773261,\n",
       " 5.834782812541814]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "c585f905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdd987ed5e0>"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(B,tr_vals,'or')\n",
    "plt.plot(B,te_vals,'ob')\n",
    "plt.xlabel(\"BTS\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend(['Trainset','Testset'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
